"""
ë‹¨ì–´ ë¶„ì„ ë° ìë™ ì ìˆ˜í™” ëª¨ë“ˆ
- ë‹¨ì–´ì™€ ë§¤ì¶œ ë°ì´í„°ë¥¼ í•™ìŠµí•˜ì—¬ ë‹¨ì–´ë³„ ì¤‘ìš”ë„(ì ìˆ˜) ìë™ ì‚°ì¶œ
- ë§¤ì¶œ ë³€í™”ì— ëŒ€í•œ ì„¤ëª… ìƒì„±
"""

import numpy as np
import pandas as pd
from typing import Dict, List, Tuple, Optional
from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import Ridge, Lasso
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
import json
from pathlib import Path


class WordAnalyzer:
    """ë‹¨ì–´ ë¶„ì„ ë° ìë™ ì ìˆ˜í™” í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.word_to_index = {}
        self.index_to_word = {}
        self.word_scores = {}
        self.feature_importance = {}
        self.model = None
        self.scaler = StandardScaler()
        
    def load_word_data(self, input_data_path: str) -> Dict[str, List[str]]:
        """
        ì›”ë³„ ë‹¨ì–´ ë°ì´í„° ë¡œë”© (ì ìˆ˜ ì—†ì´ ë‹¨ì–´ë§Œ)
        
        Args:
            input_data_path: ë‹¨ì–´ ë°ì´í„° ê²½ë¡œ
            
        Returns:
            {ì›”: [ë‹¨ì–´1, ë‹¨ì–´2, ...]} í˜•íƒœì˜ ë”•ì…”ë„ˆë¦¬
        """
        word_data = {}
        input_path = Path(input_data_path)
        
        if not input_path.exists():
            print(f"ê²½ê³ : {input_path} ê²½ë¡œê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
            return word_data
        
        # JSON íŒŒì¼ë“¤ ë¡œë”©
        for file_path in input_path.glob("*.json"):
            file_month = file_path.stem
            
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    
                    # ë‹¨ì–´ ë¦¬ìŠ¤íŠ¸ ë˜ëŠ” ë‹¨ì–´-ì ìˆ˜ ë”•ì…”ë„ˆë¦¬ ì²˜ë¦¬
                    if isinstance(data, list):
                        # ë‹¨ì–´ ë¦¬ìŠ¤íŠ¸ì¸ ê²½ìš°
                        word_data[file_month] = data
                    elif isinstance(data, dict):
                        # ë‹¨ì–´-ì ìˆ˜ ë”•ì…”ë„ˆë¦¬ì¸ ê²½ìš° (ë‹¨ì–´ë§Œ ì¶”ì¶œ)
                        word_data[file_month] = list(data.keys())
                    else:
                        print(f"ê²½ê³ : {file_path} í˜•ì‹ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤.")
            except Exception as e:
                print(f"ê²½ê³ : {file_path} ë¡œë”© ì‹¤íŒ¨: {e}")
        
        return word_data
    
    def build_vocabulary(self, word_data: Dict[str, List[str]]) -> Dict[str, int]:
        """
        ì „ì²´ ë‹¨ì–´ ì‚¬ì „ êµ¬ì¶•
        
        Args:
            word_data: {ì›”: [ë‹¨ì–´ ë¦¬ìŠ¤íŠ¸]}
            
        Returns:
            {ë‹¨ì–´: ì¸ë±ìŠ¤} ë”•ì…”ë„ˆë¦¬
        """
        all_words = set()
        for words in word_data.values():
            all_words.update(words)
        
        self.word_to_index = {word: idx for idx, word in enumerate(sorted(all_words))}
        self.index_to_word = {idx: word for word, idx in self.word_to_index.items()}
        
        print(f"ì „ì²´ ë‹¨ì–´ ìˆ˜: {len(self.word_to_index)}")
        return self.word_to_index
    
    def words_to_vector(self, words: List[str]) -> np.ndarray:
        """
        ë‹¨ì–´ ë¦¬ìŠ¤íŠ¸ë¥¼ ë²¡í„°ë¡œ ë³€í™˜ (ì›-í•« ì¸ì½”ë”©)
        
        Args:
            words: ë‹¨ì–´ ë¦¬ìŠ¤íŠ¸
            
        Returns:
            ë‹¨ì–´ ë²¡í„° (0 ë˜ëŠ” 1)
        """
        vector = np.zeros(len(self.word_to_index))
        for word in words:
            if word in self.word_to_index:
                vector[self.word_to_index[word]] = 1.0
        return vector
    
    def prepare_training_data(self, 
                             word_data: Dict[str, List[str]], 
                             sales_data: pd.DataFrame) -> Tuple[np.ndarray, np.ndarray, List[str]]:
        """
        í•™ìŠµ ë°ì´í„° ì¤€ë¹„
        
        Args:
            word_data: {ì›”: [ë‹¨ì–´ ë¦¬ìŠ¤íŠ¸]}
            sales_data: ë§¤ì¶œ ë°ì´í„°í”„ë ˆì„
            
        Returns:
            (X, y, months) - ë‹¨ì–´ ë²¡í„°, ë§¤ì¶œ ê°’, ì›” ë¦¬ìŠ¤íŠ¸
        """
        # ì‚¬ì „ êµ¬ì¶•
        self.build_vocabulary(word_data)
        
        X_list = []
        y_list = []
        months_list = []
        
        # ë§¤ì¶œ ë°ì´í„°ì—ì„œ ì›” ì¶”ì¶œ
        if 'month' in sales_data.columns:
            sales_data['month_str'] = pd.to_datetime(sales_data['month']).dt.strftime('%Y-%m')
        
        for month, words in word_data.items():
            # í•´ë‹¹ ì›”ì˜ ë§¤ì¶œ ë°ì´í„° ì°¾ê¸°
            if 'month_str' in sales_data.columns:
                sales_row = sales_data[sales_data['month_str'] == month]
            else:
                sales_row = pd.DataFrame()
            
            if not sales_row.empty and 'sales' in sales_row.columns:
                word_vector = self.words_to_vector(words)
                sales_value = sales_row['sales'].values[0]
                
                X_list.append(word_vector)
                y_list.append(sales_value)
                months_list.append(month)
        
        if not X_list:
            raise ValueError("ë§¤ì¹­ë˜ëŠ” ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ë‚ ì§œ í˜•ì‹ì„ í™•ì¸í•˜ì„¸ìš”.")
        
        X = np.array(X_list)
        y = np.array(y_list)
        
        print(f"í•™ìŠµ ë°ì´í„°: {len(X)}ê°œì›”")
        return X, y, months_list
    
    def learn_word_scores(self, 
                         X: np.ndarray, 
                         y: np.ndarray,
                         method: str = 'gradient_boosting') -> Dict[str, float]:
        """
        ë‹¨ì–´ë³„ ì ìˆ˜(ì¤‘ìš”ë„) í•™ìŠµ
        
        Args:
            X: ë‹¨ì–´ ë²¡í„°
            y: ë§¤ì¶œ ê°’
            method: í•™ìŠµ ë°©ë²• ('ridge', 'lasso', 'random_forest', 'gradient_boosting')
            
        Returns:
            {ë‹¨ì–´: ì ìˆ˜} ë”•ì…”ë„ˆë¦¬
        """
        # ë°ì´í„° ì •ê·œí™”
        X_scaled = self.scaler.fit_transform(X)
        
        # ëª¨ë¸ ì„ íƒ ë° í•™ìŠµ
        if method == 'ridge':
            self.model = Ridge(alpha=1.0)
        elif method == 'lasso':
            self.model = Lasso(alpha=0.1)
        elif method == 'random_forest':
            self.model = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)
        elif method == 'gradient_boosting':
            self.model = GradientBoostingRegressor(n_estimators=100, random_state=42)
        else:
            raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ë°©ë²•: {method}")
        
        self.model.fit(X_scaled, y)
        
        # íŠ¹ì„± ì¤‘ìš”ë„ ì¶”ì¶œ
        if method in ['ridge', 'lasso']:
            importance = self.model.coef_
        else:
            importance = self.model.feature_importances_
        
        # ì •ê·œí™”ëœ ì ìˆ˜ ê³„ì‚° (0~1 ë²”ìœ„)
        importance_abs = np.abs(importance)
        if importance_abs.max() > 0:
            normalized_scores = importance_abs / importance_abs.max()
        else:
            normalized_scores = importance_abs
        
        # ë‹¨ì–´ë³„ ì ìˆ˜ ì €ì¥
        self.word_scores = {}
        self.feature_importance = {}
        
        for idx, score in enumerate(importance):
            word = self.index_to_word[idx]
            self.word_scores[word] = float(normalized_scores[idx])
            self.feature_importance[word] = {
                'score': float(normalized_scores[idx]),
                'raw_importance': float(importance[idx]),
                'direction': 'positive' if importance[idx] > 0 else 'negative'
            }
        
        # ì ìˆ˜ ìˆœìœ¼ë¡œ ì •ë ¬
        self.word_scores = dict(sorted(
            self.word_scores.items(), 
            key=lambda x: x[1], 
            reverse=True
        ))
        
        print(f"\n=== ë‹¨ì–´ë³„ í•™ìŠµëœ ì ìˆ˜ ===")
        for i, (word, score) in enumerate(self.word_scores.items()):
            if i < 10:  # ìƒìœ„ 10ê°œë§Œ ì¶œë ¥
                direction = self.feature_importance[word]['direction']
                print(f"  {word}: {score:.4f} ({direction})")
        
        return self.word_scores
    
    def explain_sales(self, 
                     month: str, 
                     words: List[str], 
                     predicted_sales: float,
                     actual_sales: Optional[float] = None) -> Dict:
        """
        ë§¤ì¶œì— ëŒ€í•œ ì„¤ëª… ìƒì„±
        
        Args:
            month: ì›”
            words: í•´ë‹¹ ì›”ì˜ ë‹¨ì–´ ë¦¬ìŠ¤íŠ¸
            predicted_sales: ì˜ˆì¸¡ ë§¤ì¶œ
            actual_sales: ì‹¤ì œ ë§¤ì¶œ (ì„ íƒ)
            
        Returns:
            ì„¤ëª… ë”•ì…”ë„ˆë¦¬
        """
        # ë‹¨ì–´ë³„ ì˜í–¥ë„ ê³„ì‚°
        word_impacts = []
        for word in words:
            if word in self.feature_importance:
                info = self.feature_importance[word]
                word_impacts.append({
                    'word': word,
                    'score': info['score'],
                    'direction': info['direction'],
                    'impact': 'high' if info['score'] > 0.7 else 'medium' if info['score'] > 0.3 else 'low'
                })
        
        # ì˜í–¥ë„ ìˆœìœ¼ë¡œ ì •ë ¬
        word_impacts.sort(key=lambda x: x['score'], reverse=True)
        
        # ê¸ì •/ë¶€ì • ë‹¨ì–´ ë¶„ë¦¬
        positive_words = [w for w in word_impacts if w['direction'] == 'positive']
        negative_words = [w for w in word_impacts if w['direction'] == 'negative']
        
        # ì„¤ëª… ìƒì„±
        explanation = {
            'month': month,
            'predicted_sales': predicted_sales,
            'actual_sales': actual_sales,
            'total_words': len(words),
            'analyzed_words': len(word_impacts),
            'top_positive_factors': positive_words[:5],
            'top_negative_factors': negative_words[:5],
            'summary': self._generate_summary(positive_words, negative_words, predicted_sales)
        }
        
        return explanation
    
    def _generate_summary(self, 
                         positive_words: List[Dict], 
                         negative_words: List[Dict],
                         predicted_sales: float) -> str:
        """ì„¤ëª… ìš”ì•½ ìƒì„±"""
        summary_parts = []
        
        if positive_words:
            top_positive = [w['word'] for w in positive_words[:3]]
            summary_parts.append(f"ë§¤ì¶œ ìƒìŠ¹ ìš”ì¸: {', '.join(top_positive)}")
        
        if negative_words:
            top_negative = [w['word'] for w in negative_words[:3]]
            summary_parts.append(f"ë§¤ì¶œ í•˜ë½ ìš”ì¸: {', '.join(top_negative)}")
        
        if not summary_parts:
            summary_parts.append("ë¶„ì„ëœ ì£¼ìš” ìš”ì¸ì´ ì—†ìŠµë‹ˆë‹¤.")
        
        summary = " | ".join(summary_parts)
        return summary
    
    def save_word_scores(self, output_path: str):
        """í•™ìŠµëœ ë‹¨ì–´ ì ìˆ˜ ì €ì¥"""
        output = {
            'word_scores': self.word_scores,
            'feature_importance': self.feature_importance
        }
        
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(output, f, ensure_ascii=False, indent=2)
        
        print(f"ë‹¨ì–´ ì ìˆ˜ ì €ì¥: {output_path}")
    
    def load_word_scores(self, input_path: str):
        """ì €ì¥ëœ ë‹¨ì–´ ì ìˆ˜ ë¡œë“œ"""
        with open(input_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        self.word_scores = data['word_scores']
        self.feature_importance = data['feature_importance']
        
        print(f"ë‹¨ì–´ ì ìˆ˜ ë¡œë“œ: {input_path}")
    
    def get_top_words(self, n: int = 10, direction: str = 'all') -> List[Tuple[str, float]]:
        """
        ìƒìœ„ Nê°œ ë‹¨ì–´ ë°˜í™˜
        
        Args:
            n: ë°˜í™˜í•  ë‹¨ì–´ ìˆ˜
            direction: 'all', 'positive', 'negative'
            
        Returns:
            [(ë‹¨ì–´, ì ìˆ˜)] ë¦¬ìŠ¤íŠ¸
        """
        if direction == 'all':
            words = list(self.word_scores.items())[:n]
        elif direction == 'positive':
            words = [(w, s) for w, s in self.word_scores.items() 
                    if self.feature_importance[w]['direction'] == 'positive'][:n]
        elif direction == 'negative':
            words = [(w, s) for w, s in self.word_scores.items() 
                    if self.feature_importance[w]['direction'] == 'negative'][:n]
        else:
            words = list(self.word_scores.items())[:n]
        
        return words


class SalesExplainer:
    """ë§¤ì¶œ ì„¤ëª… ìƒì„± í´ë˜ìŠ¤"""
    
    def __init__(self, word_analyzer: WordAnalyzer):
        self.word_analyzer = word_analyzer
    
    def explain_month(self, 
                     month: str, 
                     words: List[str], 
                     predicted_sales: float,
                     actual_sales: Optional[float] = None) -> str:
        """
        íŠ¹ì • ì›”ì˜ ë§¤ì¶œ ì„¤ëª… ìƒì„±
        
        Args:
            month: ì›”
            words: ë‹¨ì–´ ë¦¬ìŠ¤íŠ¸
            predicted_sales: ì˜ˆì¸¡ ë§¤ì¶œ
            actual_sales: ì‹¤ì œ ë§¤ì¶œ
            
        Returns:
            ì„¤ëª… ë¬¸ìì—´
        """
        explanation = self.word_analyzer.explain_sales(month, words, predicted_sales, actual_sales)
        
        report = []
        report.append(f"\n{'='*60}")
        report.append(f"ğŸ“Š {month} ë§¤ì¶œ ë¶„ì„ ë³´ê³ ì„œ")
        report.append(f"{'='*60}")
        
        if actual_sales:
            report.append(f"ì‹¤ì œ ë§¤ì¶œ: {actual_sales:,.0f}ì›")
        report.append(f"ì˜ˆì¸¡ ë§¤ì¶œ: {predicted_sales:,.0f}ì›")
        
        if actual_sales:
            diff = predicted_sales - actual_sales
            diff_pct = (diff / actual_sales) * 100
            report.append(f"ì˜¤ì°¨: {diff:,.0f}ì› ({diff_pct:+.1f}%)")
        
        report.append(f"\nğŸ“ˆ ë§¤ì¶œ ìƒìŠ¹ ìš”ì¸ (Top 5):")
        for factor in explanation['top_positive_factors']:
            impact_emoji = 'ğŸ”´' if factor['impact'] == 'high' else 'ğŸŸ¡' if factor['impact'] == 'medium' else 'ğŸŸ¢'
            report.append(f"  {impact_emoji} {factor['word']}: ì¤‘ìš”ë„ {factor['score']:.2f}")
        
        if explanation['top_negative_factors']:
            report.append(f"\nğŸ“‰ ë§¤ì¶œ í•˜ë½ ìš”ì¸ (Top 5):")
            for factor in explanation['top_negative_factors']:
                impact_emoji = 'ğŸ”´' if factor['impact'] == 'high' else 'ğŸŸ¡' if factor['impact'] == 'medium' else 'ğŸŸ¢'
                report.append(f"  {impact_emoji} {factor['word']}: ì¤‘ìš”ë„ {factor['score']:.2f}")
        
        report.append(f"\nğŸ’¡ ìš”ì•½: {explanation['summary']}")
        report.append(f"{'='*60}\n")
        
        return '\n'.join(report)
    
    def explain_all_months(self, 
                          word_data: Dict[str, List[str]], 
                          sales_data: pd.DataFrame,
                          predictions: Optional[Dict[str, float]] = None) -> str:
        """ì „ì²´ ì›”ì— ëŒ€í•œ ë¶„ì„ ë³´ê³ ì„œ ìƒì„±"""
        reports = []
        
        if 'month' in sales_data.columns:
            sales_data['month_str'] = pd.to_datetime(sales_data['month']).dt.strftime('%Y-%m')
        
        for month, words in sorted(word_data.items()):
            # ì‹¤ì œ ë§¤ì¶œ ì°¾ê¸°
            if 'month_str' in sales_data.columns:
                sales_row = sales_data[sales_data['month_str'] == month]
                actual_sales = sales_row['sales'].values[0] if not sales_row.empty else None
            else:
                actual_sales = None
            
            # ì˜ˆì¸¡ ë§¤ì¶œ
            predicted_sales = predictions.get(month, actual_sales) if predictions else actual_sales
            
            if predicted_sales:
                report = self.explain_month(month, words, predicted_sales, actual_sales)
                reports.append(report)
        
        return '\n'.join(reports)

